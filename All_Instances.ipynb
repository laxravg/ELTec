{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U33WtxLp-cRR",
        "outputId": "7cbea232-3538-4a25-b666-bfbf410f5502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install spacy\n",
        "!python -m spacy download es_core_news_sm\n",
        "! pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3-RxyLj-fYh",
        "outputId": "a5fcccdc-6f5a-4e80-958e-69e33df801f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: es-core-news-sm\n",
            "Successfully installed es-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "ks4Sdvxq-mjh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "\n",
        "sentiment_analyzer = pipeline(\"text-classification\", model=\"tabularisai/multilingual-sentiment-analysis\")\n",
        "\n",
        "route = \"/content/drive/MyDrive/Colab.Notebooks/Digital Humanities/Project/Spanish_ELTec_Corpus\"\n",
        "files = glob.glob(os.path.join(route, \"*_annotated.xml\"))\n",
        "\n",
        "# Key words\n",
        "key_words = [\n",
        "    \"Francia\", \"Inglaterra\", \"París\", \"Roma\", \"Italia\", \"Flandes\", \"Londres\",\n",
        "    \"América\", \"Portugal\", \"Nápoles\", \"Maya\", \"Fátima\", \"Alemania\", \"Rajatul-laj\",\n",
        "    \"Occidente\", \"Austria\", \"África\", \"Túnez\", \"Birmingham\", \"Habana\", \"Lisboa\",\n",
        "    \"Cuba\", \"Bruselas\", \"Méjico\", \"Biarritz\", \"Indias\", \"Asia\", \"Egipto\",\n",
        "    \"Constantinopla\", \"Holanda\", \"Damasco\", \"Filipinas\", \"India\", \"Bretaña\",\n",
        "    \"Rusia\", \"Grecia\", \"Escocia\"\n",
        "]\n",
        "\n",
        "def extract_tokens(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    ns = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
        "    tokens = []\n",
        "    for w in root.findall('.//tei:w', ns):\n",
        "        text = w.text\n",
        "        if text:\n",
        "            tokens.append({\n",
        "                \"text\": text,\n",
        "                \"pos\": w.attrib.get(\"pos\", \"\"),\n",
        "                \"lemma\": w.attrib.get(\"lemma\", \"\"),\n",
        "                \"ner\": w.attrib.get(\"ner\", \"\")\n",
        "            })\n",
        "    return tokens\n",
        "\n",
        "# Obtain the year of publication in order to compare periods\n",
        "def get_year(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    ns = {'tei': 'http://www.tei-c.org/ns/1.0'}\n",
        "    date_node = root.find('.//tei:sourceDesc//tei:bibl[@type=\"firstEdition\"]/tei:date', ns)\n",
        "    if date_node is not None and date_node.text and date_node.text.strip().isdigit():\n",
        "        return int(date_node.text.strip())\n",
        "    return None\n",
        "\n",
        "# Classify the years in 2 decade periods\n",
        "def classify_year(year):\n",
        "    if year is None:\n",
        "        return \"unknown\"\n",
        "    if 1840 <= year <= 1859:\n",
        "        return \"1840-1859\"\n",
        "    elif 1860 <= year <= 1879:\n",
        "        return \"1860-1879\"\n",
        "    elif 1880 <= year <= 1899:\n",
        "        return \"1880-1899\"\n",
        "    elif 1900 <= year <= 1920:\n",
        "        return \"1900-1920\"\n",
        "    return \"Out of range\"\n",
        "\n",
        "# Get windows of text\n",
        "def windows(tokens, key_word, file_, period, window=100):\n",
        "    windows = []\n",
        "    for i, token in enumerate(tokens):\n",
        "        if token[\"text\"] == key_word:\n",
        "            start = max(i - window, 0)\n",
        "            end = min(i + window + 1, len(tokens))\n",
        "            context = \" \".join([tok[\"text\"] for tok in tokens[start:end]])\n",
        "            windows.append({\n",
        "                \"key_word\": key_word,\n",
        "                \"text_window\": context,\n",
        "                \"file\": os.path.basename(file_),\n",
        "                \"period\": period\n",
        "            })\n",
        "    return windows\n",
        "\n",
        "# Get all the windows that contain the key_word\n",
        "all_windows = []\n",
        "\n",
        "for file_ in tqdm(files, desc=\"Processing all files\"):\n",
        "    year = get_year(file_)\n",
        "    period = classify_year(year)\n",
        "    tokens = extract_tokens(file_)\n",
        "\n",
        "    for word in key_words:\n",
        "        new = windows(tokens, word, file_, period)\n",
        "        all_windows.extend(new)\n",
        "\n",
        "# Sentiment Analysis in all the windows that have one key_word on the text\n",
        "for window in tqdm(all_windows, desc=\"Analyzing sentiments\"):\n",
        "    try:\n",
        "        result = sentiment_analyzer(window[\"text_window\"][:512])[0]\n",
        "        window[\"sentiment\"] = result[\"label\"]\n",
        "        window[\"confidence_score\"] = result[\"score\"]\n",
        "    except Exception as e:\n",
        "        window[\"sentiment\"] = \"error\"\n",
        "        window[\"confidence_score\"] = 0.0\n",
        "\n",
        "\n",
        "df = pd.DataFrame(all_windows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgLTQHBj-nLE",
        "outputId": "f4424928-801b-4e97-879f-52c6fde26986"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Processing all files: 100%|██████████| 87/87 [03:17<00:00,  2.27s/it]\n",
            "Analyzing sentiments: 100%|██████████| 4992/4992 [20:29<00:00,  4.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = df.sort_values(by=[\"key_word\", \"confidence_score\"], ascending=[True, False])\n",
        "df_all.to_csv(\"/content/drive/MyDrive/Colab.Notebooks/Digital Humanities/Project/data/all_countries.csv\", index=False)"
      ],
      "metadata": {
        "id": "bNR7GCPYFR99"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the number of total files per period"
      ],
      "metadata": {
        "id": "kCADiwgLApDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.read_csv(\"/content/drive/MyDrive/Colab.Notebooks/Digital Humanities/Project/data/all_countries.csv\")\n",
        "df_all['period'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "Y9ZZR_-D_E_H",
        "outputId": "081e80a3-dcb7-46c1-d158-80ee6bc4cb43"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "period\n",
              "1900-1920    2051\n",
              "1840-1859    1039\n",
              "1880-1899     907\n",
              "1860-1879     677\n",
              "unknown       318\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>period</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1900-1920</th>\n",
              "      <td>2051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1840-1859</th>\n",
              "      <td>1039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1880-1899</th>\n",
              "      <td>907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1860-1879</th>\n",
              "      <td>677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unknown</th>\n",
              "      <td>318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counting = df_all.groupby('key_word')['sentiment'].value_counts().unstack(fill_value=0)\n",
        "print(counting)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqmCo7EnAdh8",
        "outputId": "bfec52d8-2501-4258-c851-9a240052c81a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment       Negative  Neutral  Positive  Very Negative  Very Positive\n",
            "key_word                                                                 \n",
            "Alemania               7       13        20             41             25\n",
            "América                5        9        25             61             64\n",
            "Asia                   1        4         8             22             13\n",
            "Austria                6       37       117            158            128\n",
            "Biarritz               0        5        10             17             22\n",
            "Birmingham             5        7        15             25             18\n",
            "Bretaña                2        3         9             17             11\n",
            "Bruselas               2        2        14             35             16\n",
            "Constantinopla         2        2        10             23             11\n",
            "Cuba                   2        4         7             27             20\n",
            "Damasco                0        0         5              2              1\n",
            "Egipto                 0        5         8             12             18\n",
            "Escocia                0        2        11              8              8\n",
            "Filipinas              4        3         9             15             12\n",
            "Flandes                7       18        50            116             50\n",
            "Francia                9       32        90            176            107\n",
            "Fátima                 2        6        17             90             58\n",
            "Grecia                 0        2         6             13             14\n",
            "Habana                 2        4        13             28             19\n",
            "Holanda                0        5         7             15             16\n",
            "India                  1        2         5             14             19\n",
            "Indias                 1        6         8             25             15\n",
            "Inglaterra            16       57        70            171             86\n",
            "Italia                 2       11        48            104             82\n",
            "Lisboa                 3        4        14             36             17\n",
            "Londres               12       30        31             97             51\n",
            "Maya                   3       18        40             42             22\n",
            "Méjico                 0        1         6             27             21\n",
            "Nápoles                0        6        34             53             48\n",
            "Occidente              1        8        13             48             24\n",
            "París                 13       28        82            241            158\n",
            "Portugal               1       12        38             66             49\n",
            "Rajatul-laj            4        8         9             49             35\n",
            "Roma                   6       24        73            118             99\n",
            "Rusia                  1        3        10             14              9\n",
            "Túnez                  1        6        20             34             16\n",
            "África                 2       10        25             40             33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the number of selected files per period"
      ],
      "metadata": {
        "id": "sQLHlhQ4Aup8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "df_all['file'] = df_all['file'].astype(str)\n",
        "\n",
        "# Modifying the incorrect labeled files\n",
        "periods = {\n",
        "    'SPA3029_Blanco_Cercado_annotated.xml': '1880-1899',\n",
        "    'SPA2021_RafaelDelCastillo_LosCaballerosDelAmor_annotated.xml': '1860-1879',\n",
        "    'SPA3002_LeopoldoAlas_LaRegenta_annotated.xml': '1900-1920',\n",
        "    'SPA1022_GomezDeAvellaneda_DosMujeres_annotated.xml': '1840-1859'\n",
        "}\n",
        "\n",
        "\n",
        "for file, period in periods.items():\n",
        "    df_all.loc[df['file'] == file, 'period'] = period\n",
        "\n",
        "# Collapsing the labels into 2 and droping the Neutral instances\n",
        "reduced_sentiment = {\n",
        "    'Very Negative': 'Negative',\n",
        "    'Very Positive': 'Positive',\n",
        "    'Neutral': None\n",
        "}\n",
        "\n",
        "df_all['sentiment'] = df_all['sentiment'].map(reduced_sentiment)\n",
        "df_all = df_all.dropna(subset=['sentiment'])\n",
        "\n",
        "# Selecting only some countries to analyse\n",
        "countries = ['Cuba', 'Asia', 'América', 'Egipto', 'Filipinas']\n",
        "regex = '|'.join(map(re.escape, countries))\n",
        "df_selected = df_all[df_all['key_word'].str.contains(regex, case=False, na=False)]\n"
      ],
      "metadata": {
        "id": "UYfe-SaCAxjP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_selected['period'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "huB4JpwWCKXk",
        "outputId": "6ef0a097-7399-4c5a-ec92-38463f78e553"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "period\n",
              "1860-1879    83\n",
              "1880-1899    68\n",
              "1900-1920    52\n",
              "unknown      32\n",
              "1840-1859    29\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>period</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1860-1879</th>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1880-1899</th>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1900-1920</th>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unknown</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1840-1859</th>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counting = df_selected.groupby('key_word')['sentiment'].value_counts().unstack(fill_value=0)\n",
        "print(counting)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypoyzWBBCMbx",
        "outputId": "2979ced5-b5fb-4c65-acd7-2141fc17e8d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentiment  Negative  Positive\n",
            "key_word                     \n",
            "América          61        64\n",
            "Asia             22        13\n",
            "Cuba             27        20\n",
            "Egipto           12        18\n",
            "Filipinas        15        12\n"
          ]
        }
      ]
    }
  ]
}